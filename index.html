<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8' />
    <meta http-equiv="X-UA-Compatible" content="chrome=1" />
    <meta name="description" content="Aama.github.io : Afro-Asiatic Morphology Archive" />

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

      <title>aama</title>
    </head>

    <body>

      <!-- HEADER -->
      <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/aama">View on GitHub</a>

          <h1 id="project_title">aama</h1>
          <h2 id="project_tagline">Afro-Asiatic Morphology Archive</h2>

        </header>
      </div>

      <!-- MAIN CONTENT -->
      <div id="main_content_wrap" class="outer">
	<section id="main_content" class="inner">
          <h3>
	  <a name="welcome-to-aama---the-afro-asiatic-morphology-archive" class="anchor" href="#welcome-to-aama---the-afro-asiatic-morphology-archive"><span class="octicon octicon-link"></span></a>Welcome to AAMA - the Afro-Asiatic Morphology Archive.</h3>

	  <h4>Getting Started</h4>

	  <h5>Overview</h5>
	  <ol>
	    <li><a href="#software">Install and configure required software</a></li>
	    <li><a href="#datatools">Download data and tools</a></li>
	    <li><a href="#ednformat">The EDN format for morphological data</a></li>
	    <li><a href="#rdfgen">Generate RDF data from morphological data files</a></li>
	    <li><a href="#rdfupload">Upload RDF data to SPARQL service</a></li>
	    <li><a href="#aamaquery">Query SPARQL service</a></li>
	  </ol>
	    <p><a href="#datastructure">Appendix: The Data Schema</a></p>

	  <h5>Details</h5>
	  <ol>
	    <li id="software">
	      <h6>Install and configure required software</h6>
	      <ol>
		<li>
		  <h6>Git client</h6>
		  <p>The aama project uses <a
		  href="http://github.com">GitHub</a> to store data
		  and tools; you'll need a git client in order to
		  download the tools repository and the data
		  repositories you're interested in.  Follow the
		  instructions at <a
		  href="https://help.github.com/articles/set-up-git#platform-mac">Set
		  Up Git</a>.
		  </p>
		  <p>Note that you do not need to create a github
		  account unless you want to edit the data or code.
		  Instructions for how to do that are below.
		  </p>
		</li>
		<li>
		  <p>
		    Create and switch to an <code>aama</code> directory
		    structure on your local drive, e.g.
		    <pre>
~/ $ mkdir aama
~/ $ cd aama</pre>
		  </p>
		</li>
		<li>
		  <h6>rdf2rdf.jar</h6>
		  <p>We use this tool to convert RDF files to various
		  formats.  <a
		  href="http://www.l3s.de/~minack/rdf2rdf/">Download
		  it</a> and save it someplace convenient -
		  <code>~/aama/jar</code> is a good place.
		  </p>
		</li>
		<li>
		  <h6>Fuseki</h6>
		  <p>
		    Fuseki is the SPARQL server we are using to query the dataset.  <a
		    href="http://jena.apache.org/download/index.cgi">Download</a>
		    the <code>apache-jena-fuseki-2.4.0-distribution</code>
		    distribution (either the zip file or the tar file; NB, make
		    sure your Java JDK is up-to-date with the download)
		    and store it in a convenient location.
		    <code>~/aama/fuseki</code> is a good place.
		   The following steps will install the <code>aama</code> dataset
		    and verify that it runs. Futher information about Fuseki, 
		    as well as information and links about RDF linked data and
		    the SPARQL query language can be found at the
		    <a href="http://jena.apache.org/index.html"> Apache Jena</a> 
		    site. </p>
		</li>
	      </ol>
	    </li>
	    <li id="datatools">
	      <h6>Download data and tools</h6>
	      <ul>
		<li>
		  <p>Take a look at the <a
		  href="https://github.com/aama">Aama repositories</a> and
		  decide which languages interest you.  In general we use
		  one repository per language, or in some cases, language 
		  variety, e.g. <a
		  href="https://github.com/aama/beja-arteiga">beja-arteiga</a>,
		  <a
		      href="https://github.com/aama/beja-bishari">beja-bishari</a>,
		  etc.
		  </p>
		  <p>Now you need to download the data to your local
		  harddrive.  Create a <code>data</code> directory
		  inside the <code>aama</code> directory,
		  e.g. <code>~/aama $ mkdir data</code>. Then clone
		  each language repository into the data directory:
		  </p>
		  <pre>
~/ $ cd aama/data
~/aama/data $ git clone https://github.com/aama/afar.git
~/aama/data $ git clone https://github.com/aama/geez.git
~/aama/data $ git clone https://github.com/aama/yemsa.git</pre>
		  <p>
		    Alternatively, you can create a personal github
		    account, <i>fork</i> the aama repositories (copy them
		    to your account), and then clone your repositories to
		    your local drive.  See <a
		    href="https://help.github.com/articles/fork-a-repo">Fork
		    a Repo</a> for details.
		  </p>
		</li>
		<li>
		  <p>
		    In the same <code>aama</code> directory, clone the
		    aama <a href="https://github.com/aama/tools">tools
		    repository</a>:
		    <pre>
~/aama $ git clone https://github.com/aama/tools.git</pre>
		    and the <a href="https://github.com/aama/webapp"> web
		      application</a>:
		    <pre>
~/aama $ git clone https://github.com/aama/webapp.git</pre>
		  </p>
		</li>
	      </ul>
	      <p>
		When you're done, your directory structure should look
		like this (assuming you have cloned afar, geez, and
		yemsa):
	      </p>
		<pre>
   aama
   |-data
   |---afar
   |---geez
   |---yemsa
   |-fuseki
   |-jar
   |-tools
   |-webapp
		</pre>
	    </li>
	    <li id="ednformat">
	      <h6>The EDN format for morphological data</h6>

	      <p> The normative/persistant data format is the json-like 
		<a href="https://github.com/edn-format/edn">edn:  Extensible 
		  Data Notation</a>. This notation has the advantage of being
		rigorously defined system of terms (<code>:term</code>),
		strings (<code>"string"</code>), vectors 
		(<code>[a b c d]</code> maps (<code>{a b, c d}</code> and sets 
		(<code>#{a b c d}</code>, and thus reliably transformable 
		into a consistent RDF notation, while  at the same time 
		providing a human-readable natural format for data-entry and 
		inspection.
	      </p>
	      <p>
		Our current EDN structure (cf. <a href="#datastructure">below</a>)
		while open to extension and revision,
		seems to provide a natural notation for the verbal and 
		pronominal inflectional paradigms encountered in Afroasiatic,
		and perhaps for inflectional paradigms generally. </p>
             <p>
	       Since the EDN file is the normative/persistant data format,
	       any corrections or additions you want to make must be made 
	       in this file, from which you will then generate new TTL/RDF 
	       files to be  uploaded to the SPARQL server. And in fact, as 
	       long as you observe the above structure for EDN 
	       files, you can create any number of new language files of your
	       own, transform them to RDF format, and upload them to the
	       SPARQL server for querying.
	       </p>
	    </li>
	    <li id="rdfgen">
	      <h6>Generate RDF data from morphological data files</h6>
	      <p>
		In order to convert EDN-format data files to TTL ("turtle" 
		-- a more easily human-readable RDF format), you will
		need the <code>aama-edn2ttl.jar</code> file.
		You will find this file in the <code>~/aama/tools/clj</code> 
		directory, which also contains its source-code. You should
		move this file to wherever you saved the rdf2rdf.jar file
		(for example in <code>~/aama/jar</code>), which in turn will
		convert the .ttl file to the rdf-xml which is needed for
		uploading to the Fuseki SPARQL service.
	      </p>
	      <p>
		The EDN->TTL->RDF conversion can be effected by running:
		<pre>
~/aama $ tools/bin/aama-edn2rdf.sh "data/*"
                </pre>
		which will make a .ttl and .rdf file for every .edn file
		in the data/ directory. This script presumes that the two
		jar files have been placed in <code>~/aama/jar</code>; you
		should edit it if the jar files have been located elsewhere.
		(The conversion of a single language file can be effected by
		substituting, e.g., <code>data/oromo</code> for 
		<code>"data/*"</code>.) 
		</p>
	    </li>
	    <li id="rdfupload">
	      <h6>Upload RDF data to SPARQL service</h6>
	      <p>
		In order to upload the RDF files to Fuseki, you must
		first start the server by running:
		<pre>
~/aama $ tools/bin/fuseki.sh
                </pre>
		This script, like the following, assumes that the current version
		of Fuseki, for the moment <code>apache-jena-fuseki-2.4.0</code>, has
		been placed in the <code>aama/fuseki</code> directory, and that
		the file <code>tools/aamaconfig.ttl</code> has been copied
		to the Fuseki version directory; the
                scripts should be edited for the correct locations if this
		is not the case. When run for the first time, you will notice 
		that the script, which references the configuration file 
		<code>tools/aamaconfig.ttl</code>, will have placed a, 
		for the moment empty, data
		sub-directory <code>aama</code> in the 
		<code>fuseki/apache-jena-fuseki-2.4.0/</code> directory.
		</p>
	      <p>
		The following script:
		<pre>
 ~/aama $ tools/bin/aama-rdf2fuseki.sh "data/*"
                </pre>
		will load all the rdf files in <code>aama/data</code>
		into the Fuseki server.
		</p>
	  <p>
	    You can test the upload with the script: 
	    <pre>
~/aama $ tools/bin/fuqueries.sh
            </pre>
	    which runs the queries <code>count-triples.rq</code>
	    ("How many triples are there in the datastore?") and 
	    <code>list-graphs.rq</code> ("What are the URIs of the 
	    language subgraphs?"), from the directory 
	    <code>tools/sparql/rq-ru</code>.
	    If the upload has been successful, you will see an output such as
	    the following (assuming again that afar, geez, and yemsa are the 
	    languages which have been cloned into aama/data/).</p>
	  <pre>
Query: tools/sparql/rq-ru/count-triples.rq
?sTotal
33871
Query: tools/sparql/rq-ru/list-graphs.rq
?g
&lt;http://oi.uchicago.edu/aama/2013/graph/afar>
&lt;http://oi.uchicago.edu/aama/2013/graph/geez>
&lt;http://oi.uchicago.edu/aama/2013/graph/yemsa>
	  </pre>
	  </p>

	    </li>
	    <li id="aamaquery">
	      <h6>Query SPARQL service</h6>
	      The SPARQL service can accessed to explore the morphological
	      data via three interfaces:
	      <ol>
		<li>
		  <h7>An AAMA command-line interface</h7>
		 <p>
		  (Some sample queries in <code>tools/sparql/rq-ru</code>
		  and scripts in <code>tools/bin</code>. An earlier version exists
		  with an extensive command-line application written in Perl.)</p>
		  </li>
		<li>
		  <h7>The Apache Jena Fuseki interface </h7>
		  <p>
		    You can see this on your browser at 
		    <code>localhost:3030</code> after you launch Fuseki. 
		    SPARQL queries, for example, those contained in the <code>
		      tools/sparql/rq-ru/</code> directory can be run directly 
		    against the datastore 
		    in the Fuseki Control Panel on the 
		    <code>localhost:3030/dataset.html</code> page
		    (select the <code>/aama</code>
		    dataset when prompted). 
		  </p>
		  </li>
		<li>
		  <h7>A web application specifically oriented to AAMA data</h7>
		  <p>A preliminary menu-driven web application, will have
		    already been downloaded following the instructions outlined 
		    above in <a href="#datatools">Download data and tools</a>.
		    This application demonstrates the
		    use of SPARQL query templates for display and comparison of 
		    paradigms and morphosyntactic properties and categories. 
		    It is written in <a href="http://clojure.org/index">Clojure</a>,
		    a LISP dialect with a very involved
		    community of users who have created a formidable,
		    and constantly growing set of libraries. However essentially
		    the same functionality could be achieved by any software
		    framework which can provide a web interface for handling
		    SPARQL queries submitted to an  RDF datastore,
		  </p>
		  <p>The application presupposes that the Fuseki AAMA data server
		    has been launched through the invocation of the shell-script 
		    <code>bin/fuseki.sh</code>. At present 
		    the application can be run in the webapp directory, either
		    <ol><li>from the downloaded sorce-code, with the command 
			<code>lein ring server</code> using 
		  	<a href="http://leiningen.org">Leiningen</a></li>
		        <li> or as a Java application from the jar file to be 
			  found in the webapp directory, with
			  the command <code>java -jar aama-webapp.jar</code>.</li>
			</ol>
		  </p>
		  <p> In either case, the application will be seen on the browser 
		    at <code>localhost:3000</code>. 
		    Note that, in order to run, the application must be initialized 
		    in either case by generating/loading 
		    application-specific menu and index files,
		    following the steps detailed in the 
		    <code>Help > Initialize Application</code>  menu option.
		  </li>
		</ol>
	    </li>
	  </ol>

	  <h4 id="dataschema"> Appendix: The Data Schema </h4>
	  <p>Basic structure:</p>
	      <p>In outline 
		each language EDN file has the following structure (see any of 
		the language .edn files for a concrete example, and see below 
		for explanation of terms):
		</p>
	      <pre>

{
|-:lang         <em>"language name"</em>
|-:sgpref       <em>"string representing 3-character ns prefix used for the 
|                  URI of language-specific morphosyntactic properties 
|                  and values"</em>
|-:datasource   <em>"bibliographic source(s) for the data in the file"</em>
|-:geodemoURL   <em>"on-line geo-/demo-graphical information about the language"</em>
|-:geodemoTXT   <em>"short textual summary of geo-/demographcal information"</em>
|-:schemata {	<em>"associative map of each morphosyntactic property used 
|                  in the inflectional paradigms with a vector of its values"</em>
|            }
|-:morphemes {  <em>"associative map of paradigmatic 'morphemes' with summary map
|                  of properties"</em>
|            }
|-:lexemes   {  <em>"associative map of paradigmatic 'lexemes' with summary map 
|                  of properties -- a rudimentary lexicon of paradigm lexemes"</em>
|            }
|-:lxterms   [  <em>"label-ordered vector of lexeme-derived term-clusters/paradigms,
                    each of which has the structure:"</em>
|   {
|----:label     <em>"descriptive label assigned to the term-cluster at data-entry"</em>
|----:note
|----:common    <em>"map of property-value pairs which all members of the
|                 termcluster have in common"</em>
|----:terms     <em>"vector of vectors, the first of which enumerates  the
|                  properties which differentiate individual terms, while
|                  the others list, in order, the value of the i-th
|                  property -- in fact, a paradigm for the distinct property-
|                  value pairs of the lexeme in question"</em>
|   }
|
| . . .
|
| }
|-:muterms #{   <em>"label-ordered vector of morpheme-derived 
		  term-clusters/paradigms, each of which has the structure:"</em>
|   {
|----:label     <em>"descriptive label assigned to the term-cluster at data-entry"</em>
|----:note
|----:common    <em>"map of property-value pairs which all members of the
|                 termcluster have in common"</em>
|----:terms     <em>"vector of vectors, the first of which enumerates  the
|                  properties which differentiate individual terms, while
|                  the others list, in order, the value of the i-th
|                  property -- in fact, a paradigm for the distinct property-
|                  value pairs of the morpheme in question"</em>
|   }
|
| . . .
|
| }
}

</pre>
	      <p>Terminology</p>
	  <ul>
	    <li>Term - we use "term" to refer to both "lxterms" (i.e. words) and "muterms" (i.e. morphs/morphemes).  A basic motivation is that we then get a kind of recursive structure: a term may consist of a minimal element (morph) or may be composed of other terms, so morphs, words, and multi-word structures (e.g. "has been eating") are treated equally as terms. </li>
	    <li>lxterm - a word or word-like unit of organization.  An lxterm may contain multiple words, e.g. English "has gone".</li>
	    <li>Lexeme - an abstraction that connects a collection of semantically related terms; the intuitive idea is that the "members" of a lexeme are like variations on a theme

	    <ul>
	      <li>"ordinary" lexemes like READ - joins (he) reads (present), (he) read (past), reading, etc.  In such cases the semantically related words are also related morphophonologically</li>
	      <li>"special" cases:

	      <ul>
		<li>suppletion - lexemes whose members are drawn from groups that are not related morphophonologically.  For example the lexeme GO contains (he) goes and (he) went - "went" comes from the archaic verb "wend" and is unrelated historically to the verb "go" (except via suppletion).  Another example is good - better.</li>
		<li>in some cases the relationship and etymology of the lexeme members may not be clear, but we put them in the same lexeme based on meaning/use. For example, pronouns are obviously similar in some sense but it's not clear what to do with them theoretically since they serve a great variety of functions in different languages.  We use a PRO lexeme in the archive for purely pragmatic purposes - it makes it easier to organize and manipulate the data.</li>
	      </ul>
	      </li>
	    </ul>
	    </li>
	    <li>muterm - a "morph", sub-word unit of organization; e.g. the 's' in "cats", 'en' in "wooden", 'ing' in "ranting", etc.</li>
	    <li>Morpheme - basically the morphemic counterpart to a lexeme.  Just as a lexeme can be thought of as a representation of a morpho-semantic class at the word level, the notion of morpheme is intended to represent such a class at the sub-word level.  Unfortunately the term "morpheme" is commonly used with several distinct senses; for example, /s/ and /z/ may be called morphemes, but one may also talk of the "plural morpheme" (just as one may talk of the GO lexeme).  For AAMA we would have a PL morpheme linking /s/ and /z/ muterms (or morphs).  Again, this is purely pragmatic; it makes it easier to organize and manipulate the data.</li>
	  </ul>
	</section>
      </div>

      <!-- FOOTER  -->
      <div id="footer_wrap" class="outer">
	<footer class="inner">
          <p>Published with <a href="http://pages.github.com">GitHub Pages</a></p>
	</footer>
      </div>

      

    </body>
  </html>
