<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8' />
    <meta http-equiv="X-UA-Compatible" content="chrome=1" />
    <meta name="description" content="Aama.github.io : Afro-Asiatic Morphology Archive" />

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

      <title>aama</title>
    </head>

    <body>

      <!-- HEADER -->
      <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/aama">View on GitHub</a>

          <h1 id="project_title">aama</h1>
          <h2 id="project_tagline">Afro-Asiatic Morphology Archive</h2>

        </header>
      </div>

      <!-- MAIN CONTENT -->
      <div id="main_content_wrap" class="outer">
	<section id="main_content" class="inner">
          <h3>
	  <a name="welcome-to-aama---the-afro-asiatic-morphology-archive" class="anchor" href="#welcome-to-aama---the-afro-asiatic-morphology-archive"><span class="octicon octicon-link"></span></a>Welcome to AAMA - the Afro-Asiatic Morphology Archive.</h3>

	  <h4>Getting Started(v1)</h4>

	  <h5>Overview</h5>
	  <ul style="list-style-type:none;">
	    <li><a href="#project">1. The AAMA Project</a></li>
	    <li><a href="#software">2. Install required software</a></li>
	    <li><a href="#rdfgen">3. Configure Application</a></li>
	    <li><a href="#aamaquery">4. Run Application</a></li>
	    <li><a href="#aamaupdate">5. Remote Data and Webapp Update</a></li>
	  </ul>
	    <p><a href="#dataschema">Appendix 1: The Data Schema</a></p>
	    <p><a href="#datafilelist">Appendix 2: The Data Files</a></p>

	  <h5>Details</h5>

	  <ul style="list-style-type:none;">
	    <li id="project"> 
	      <h4>1. Introduction: The AAMA Project</h4>
	      <p>The purpose of the AAMA Project is to create a morphological
		archive whose data can be:
		<ul>
		  <li>curated (edited/created) -- and hopefully shared!</li>
		  <li>inspected</li>
		  <li>manipulated</li>
		  <li>queried</li>
			<li>compared</li>
		</ul>
		on individual browsers.</p> 
	      <p>In the first instance
		the archive should  make available and comparable the major 
		morphological paradigms of some forty Cushitic and Omotic languages,
		and in the longer term help situate the morphologies of these 
		two language families within Afroasiatic. Ultimately
		we hope also that the archive and its accompanying software
		may serve as a tool for exploration of typology and structure 
		of the form of linguistic organization known as the paradigm.
	      </p>
	      <p>As presently configured tha AAMA project consists of 
		three interconnected modules:</p>
		<ul>
		<li><a href="#datafiles">Data Files</li>
		<li><a href="#rdfdatastore">RDF Datastore</li>
		<li><a href="#qinterface">Provisional Query/Display Interface</li>
		</ul>
	      <ul style="list-style-type:none;">
		<li id="datafiles">
		  <h4>1.1 Data Files</h4>
		  <p>An extensible collection of <a href="#datafilelist">data files</a>  
		    containing morphological paradigms from Afroasiatic languages.
		    The data in itself is application-neutral, and could be cast 
		    into any plausible
		    datastore format, and used in conjunction with tools and
		    query-and-display
		    applications constructed using any appropriate programming tools.</p>
		  <p>Presently archived files cover principally the verbal and pronominal
		    morphological paradigms of thirty-three Cushitic and
		    six Omotic languages. In addition there are files
		    with parallel sample data covering five Semitic languages and two varieties
		    of Egyptian -- limited Berber and Chadic data is in the process
		    of being entered. The intention behind the project is,
		    with the help of collaborators, to extend the scope
		    of the archive to include eventually as complete a 
		    representation  as possible of all branches of 
		    the Afroasiatic language complex.</p>
		  <p> Nominal paradigms are systematically included in the archive whenever
		    they have been present in the underlying monographic source. However
		    we have found that Cushitic-Omotic nominal morphosyntax does not lend 
		    itself as exhaustively to straight-forward word-level paradigmatic 
		    treatment as pronominal and verbal. We are experimenting with various 
		    consistent ways to systematically treat at least case, number, 
		    focus morphosyntax across the archive.</p>
		  <p>Informally we can define "Paradigm" in its simplest and most obvious 
		    sense as:
		    <ul>
		      <li><em>Any presentation of one or more linguistic forms 
			  ("tokens": words, affixes, clitics, stems, etc.), which share 
			  a set of morphological property/value pairs, and which vary 
			  systematically along the values of another set of 
			  properties.  </em></li>
		    </ul>
		  <p>For consistency within the archive, we are using JSON  as  
		    normative/persistent paradigm format, which allows 
		     a reasonable, human-readable/-editable 
		    approximation to traditional paradigm notation. To illustrate what is 
		    by far the most common data-structure in the archive,  the paradigm,
		    what traditionally would be termed:</p>
		  <ul>
		    <li> <em>the number, person gender paradigm  of the imperfect 
			affirmative of the  Burunge glide verb xaw-'come'</em></li>
		  </ul>
		  <p>In table form:</p>

		  <table>
		    <thead>

		      <tr>
			<th>Number </th><th>Person</th><th>Gender</th><th>Token</th>
		      </tr>
		    </thead>
		    <tbody>
		      <tr>
			<td> Singular</td><td>Person1</td><td>Commo</td><td><em>xaw</em></td>
		      </tr>
		      <tr>
			<td>Singular</td><td>Person2</td><td>Common</td><td><em>xaydă</em></td>
		      </tr>
		      <tr>
			<td>Singular</td><td>Person3</td><td>Masc</td><td><em>xay</em></td>
		      </tr>
		      <tr>
			<td>Singular</td><td>Person3</td><td>Fem</td><td><em>xaydă</em></td>
		      </tr>
		      <tr>
			<td>Plural</td><td>Person1</td><td>Common</td><td><em>xaynă</em></td>
		      </tr>
		      <tr>
			<td>Plural</td><td>Person2</td><td>Common</td><td><em>xayday</em></td>
		      </tr>
		      <tr>
			<td>Plural</td><td>Person3</td><td>Common</td><td><em>xayay</em></td>
		      </tr>
		    </tbody>
		  </table>
		<p> For the normative/persistant data format we are using
		JSON. This notation has the advantage of being
		rigorously defined system of terms (<code>:term</code>),
		strings (<code>"string"</code>), vectors 
		(<code>[a b c d]</code> maps (<code>{a b, c d}</code> and sets 
		(<code>#{a b c d}</code>, and thus reliably transformable 
		into a consistent RDF notation, while  at the same time 
		providing a human-readable natural format for data-entry and 
		inspection.
	      </p>
	      <p>
		Our current JSON structure (cf. <a href="#datastructure">below</a>)
		while open to extension and revision,
		seems to provide a natural notation for the verbal and 
		pronominal inflectional paradigms encountered in Afroasiatic,
		and perhaps for inflectional paradigms generally. </p>
		  <p>Paradigms are  formally rendered  in AAMA's JSON format by a nested 
		    data-sturucture, we call ":termcluster": where entities are either 
		    labels/indices  or data strings (enclosed in quotes); 
		    where square brackets ( "[ ]") enclose listw and braces("{ }") enclose 
		    indexed listw ("di9ctionaries"). So that the paradigm just seen in table form woud be 
		    rendered by the following data structure: </p>
		  <pre>
{"termcluster":   {"label": "burunge-VBaseImperfGlideStemBaseForm-xaw",
                 "note": "Kiessling1994 ## 7.2.2,7.2.3",
                 "common": {
                          "polarity": "Affirmative",
                          "lexeme": "xaw",
                          "pos": "Verb",
                          "stemClass": "GlideStem",
                          "tam": "Imperfect"
                          },
                          "terms": [["number", "person", "gender", "token"],
                                  ["Singular", "Person1", "Common, "xaw"]
                                  ["Singular", "Person2", "Common, "xaydă"],
                                  ["Singular", "Person3", "Masc, "xay"]
                                  ["Singular", "Person3", "Fem, "xaydă"]
                                  ["Plural", "Person1", "Common, "xaynă"],
                                  ["Plural", "Person2", "Common, "xayday"],
                                  ["Plural", "Person3", "Common, "xayay"]]
                  }
 }
		  </pre>
		  <p> Where "termcluster" is an indexed list, with a unique "label" and a "note" 
		    property, which always indicates the paradigm's published source; 
                   "common" is an indexed list of the property=value pairs 
		    common to every member of the paradigm, and the list of lists "terms" has as 
		    its first member a lit of the paradigm  term properties 
		    (= paradigm column heads), while each subsequent member list 
		    contains the values, in order, of the properties.</p>		
		  <p><em> Any or all the the data files
		    can be downloaded from the AAMA site, and 
		    corrections to the existing files and submission, for on-line
		    sharing, of new language files are hereby sollicited!</em></p>
		</li>
		<li id="pdgmlabels"><h4>Note on Paradigm Labels in AAMA</h4>
		<p>
		  In this application, for the purposes of display, comparison, 
		  modification, in the various select-lists, checkbox-lists, and 
		  text-input fields, paradigms are labeled as a comma-separated string of 
		  the shared value components of the paradigm. The property associated  with
		  each value is automatic, since we follow the convention that no two property names share
		  an identical value name. If the properties whose values consititute the rows
		  of the paradigm are not `number', `person/case`. `gender`(far and away the most frequent case), 
		they are given in a comma-separated list after a delimiter '%'.
			In the, frequently long, paradigm lists automatically 
		  generated from the JSON file by the "Create Paradigm Lists" utility, for 
		  ease in processing the first two properties are always pos 
		  (part-of-speech) and morphClass, and, for ease in reading the 
		  'property=' part of the label is omitted. Thus the full form of the label of the paradigm  
		  illustrated above would be: 
		</p>
<pre>
pos=Verb,lex=xaw,polarity=Affirmative,stemClass=Glide,tam=Imperfect%number,person,gender
</pre>
		In paractice it would be listed as:
<pre>
Verb,xaw,Affirmative,Glide,Imperfect
</pre>
			
		<p> and might occur in a list as:</p>
		<pre>.  .  .
Verb,qadid,Affirmative,DentalStem,Perfect
Verb,qadid,Affirmative,DentalStem,Subjunctive
Verb,xaw,Affirmative,GlideStem,Imperfect
Verb,xaw,Affirmative,GlideStem,Perfect
Verb,xaw,Affirmative,GlideStem,Subjunctive
. . . </pre>
		</li>

		<li id="rdfdatastore">
		  <h4>1.2 A Resource Descripton Framework (RDF) Datastore and Related Tools</h4>
		  <p>The data archive will hopefully serve a number of 
		    research and reference purposes. One such purpose is the creation of a 
		    queriable datastore, which will enable easy maiipulation and combination and comparison
                    of morphological information within and between different languages and language families. 
                    To this end we have elected to set up such a
		    datastore  using the W3C-sanctioned  
		    <a href=https://www.w3.org/RDF></a> format. </p>

		  <p>Very good introductions to RDF datastores and the associated 
		    SPARQL</a> query 
		    language can be found in their respective
			  <a href="https://www.w3.org/tr/sparql11-overview/">W3C</a> home sites. But, very 
		    basically, RDF involves:</p>
		  <ol>
		    <li><em>Identifying units of information, and assigning them URL-like 
			unique Uniform Resource Identifiers (<a href="https://www.rfc-editor.org/rfc/rfc3986">URI</a>). </em>
		      <p>For example, in a paradigm  cited above from the  burunge-pdgms.json 
			file one of the possible values of the property<em> tam </em>
			(TenseAspectMode) is <em>Imperfect</em>.  In the correspnding 
			full rdf/xml format file beja-arteiga-pdgms.rdf file, we have assigned to the property 
			<em>tam</em> the full URI:</p>
		      <pre>
<em>&lt;http://id.oi.uchicago.edu/aama/2013/burunge/tam&gt;</em>
		      </pre>
		      <p>where the first part of this URI will be common to all Burunge morphological 
                        properties and values. In the more readable  
			 <a href="https://www.w3.org/TeamSubmission/turtle/">TTL</a>
			 RDF notation format,
			this URI would be notated:
				  <pre>
<em>brn:tam</em>					  
				  </pre>
				  . while the Burunge TTL file would
                      contain in a brief abbreviation section (typically five to ten items) the entry:</p>
<pre>
<em>@prefix brn:     &lt;http://id.oi.uchicago.edu/aama/2013/burunge/&gt;</em>
</pre>
		      <p>Similarly, the value <em>Imperfect</em>, which has the URI:</p>
		      <pre>
<em>&lt;http://id.oi.uchicago.edu/aama/2013/burunge/Imperfect&gt;</em>
 		      </pre>
		      <p>would be in ttl notation:
				  <pre>
	<em>brn:Imperfect</em>			  
				  </pre>
				  </p>
		    </li>
		    <li><em>Representing the complex pieces of information involving these 
			concepts by organizing these conceptual units into tripartite 
			statements called 'triples' </em>
		      <p>Triples are conventionally noted:</p>
		      <pre>
<em>s p o . </em>
		      </pre>
		      <p>and usually, but without semantic prejudice, read: </p>
		      <pre>
'subject' 'predicate' 'object' .
		      </pre>
		      <p>For example, as one might expect, an extremely common triple in a 
			datastore like AAMA is of the form:</p>
			<pre>
paradigmTermID-s hasProperty-p withValue-o .
			</pre>
		      <p>Thus if the first term of the JSON paradigm given above had the 
			pdgmTermID <em>aama:d3c483b1</em> one of the (many) triples 
			descibing it would be (in the ttl notation):</p>
		      <pre>
aama:d3c483b1 brn:tam brn:Imperfect .
		      </pre>
		      <p>Where <em>aama:</em> is the ttl abbreviation for  </p>
		      <pre>
<em>&lt;http://id.oi.uchicago.edu/aama/2013/&gt;</em>
		      </pre>
		      <p>And the ttl representation of the first row of the paradigm might be:</p>
		      <pre>
<em>aama:d3c483b1 brn:number brn:Singular .
aama:d3c483b1 brn:person brn:Person1 .
aama:d3c483b1 brn:gender brn:Common .
aama:d3c483b1 brn:token  "xaw" .</em>
		      </pre>
		      <p>stating that 'the :person property of the term has the value 
			:Person1'</p>
		      <p>And so forth. A good way to see practically the relation between 
			the JSON data file and its RDF transform is to take a look at a paradigm
			of interest in the 
			JSON and TTL versions of a language data file of interest: e.g.
		     <pre>
burunge-pdgms:{termclusters:[{label:"brn-VerbGlideStem-xaw-ImperfectAffirmative"}]} 
		     </pre>
			and its corresponding RDF transformation in the <em>burunge-pdgms.ttl</em> file.</p>
		    </li>
                    </ol>

		  <p>Not surprisingly it takes a very large number of triples to describe 
		    even a moderately large datastore (AAMA on a recent count had 987,911).
		    But they are very rapidly produced and indexed (a few seconds per 
		    language using the AAMA pdgmDict-json2ttl.py program),  efficiently stored, 
                    and permit  extremely quick access to information for display, comparison, 
		    manipulation, and reasoning. As mentioned, among the RDF  tools in the on-line
		    material, there is a Python script for 
		    transforming the (JSON) data files into appropriate RDF datastore 
		    (ttl) format, and a set of scripts to upload data files to a local 
		    Fuseki  RDF server.</p>
                   </li>
		  </ol>


		  <p>Transformation of morphological properties and values to formal URIs, and organization
				  into sets of triples is necessary 
				  in order to build a SPARQL-queriable datastore, and also
				  valuable for distinguishing terminologies and 
			building nomenclatures and ontologies. But in practice, although RDF is an extremely interesting topic in itself, 
			  running the 
		    relevant scripts for transforming, adding to ,or correcting archive-data from the json 
		    files (usually done via an application menu choice), requires no special 
		    knowledge about RDF datastores. Some knowledge of the structure of an 
		    RDF datastore and the SQL-like SPARQL query language however IS required 
		    if you want to revise or add  a page to the webapp, submitting a new genre of
		    query to the datastore in order to extract new information.<p>
				
		    <p>Pending an on-line publicly accessible datastore, you
		    can set one up on your own  computer. Instructions
		    are given below for setting up an RDF server on an individual 
		    machine, and loading the data into it.</p>
		</li>
		<li id="qinterface" ><h4>1.3 Query/Display User Interface</h4>
		  <p> The directory 'webappy' contains a set of Python scripts which contitute 
                    the elements of a rather basic 'proof-of-concept'  application1 with a prototype interface:</p>
		  <ol>
		    <li>A set of Python scripts which index the paradigm files, set up the matrerial for the menu
                      and select lists and input forms,  and programatically transform the JSON files into
                      ttl. These are principally:
                      <pre>
pdgmDict-schemata.py
pdgmDict-lexemespy						  
pdgmDict-pvlists.py
pdgmDict-json2ttl.py
                      </pre>
                      </li>
			  <li>A set of shell scripts to launch the Fuseki datastore and add new or corected data to it, and 
			  to upload or download new or corrected data to or from the remote repsitory:
			  	<pre>
fuseki.sh
aama-datastore-update.sh
aama-cp2lngrepo.sh
aama-pulldata.sh					
				</pre>
			  </li>
                    <li>
                      A set of Python scripts to choose, display, and manipulate morphological material within
                      and between language families. For the moment we are using the native Python 
                      Tcl/tk-derived  tkinter graphic library, although we plan to return to a unified menu-based
                      browser application, similar to our earlier Clojure-based application. The principal Python
                      scripts in this version are::
                      <pre>
pdgmDisp-baseApp-PDGM.py
pdgmDisp-baseApp-GPDGM.py
pdgmDispUI-formsearch.py
                      </pre>
                      These scripts generally work as follows:
                      <ol>
                        <li>They gather requested language and morphological property and value 
		      information via an array of form selection-list, checkbox, 
		      and text-input mechanisms;</li>
		    <li>formulate them into a SPARQL query, </li>
		    <li>which is submitted to the datastore, returning a CSV response,</li> 
                      <li>which in turn is typically formatted into one or more tables
                      using 'pandas' and other Python libraries.</li>
                      </ol>
		  </ul>
		  <p>Below we give instructions for downloading, launching, and 
		    initializing the app. More details on the scripts are available in the 
		    aama/webappy
			<a href="https://github.com/aama/webappy/edit/main/README.md">README</a> .
			  Also, a brief demo video of an earlier HTML/CLOJURE version can be seen at 
		    <a href="https://youtu.be/JNCJsR28SEE">AAMA DEMO</a>
		</li>
	      </ul>
	    </li>
	    <li id="software">
	      <h4>2. How to Install and configure required software</h4>
			<p>Although it is anticipated that the AAMA digital application will eventually have a
				home where its data and be consulted, and to a certain extent manipulated, online we anticipate that
			most users will want to download the application and a selection (or all!) of the data, and work
			with it on their own machine, perhaps including data of their own, which they might wish to propose uploading
			to the home site, along with proposals for modifications and additions to the data-manipulation software.</p>
			<p>At the moment, pending the creation of an executable of the `.exe` or '.jar` type what we can propose, in addition
				to the downloading of a choice of the data files of interest, is the downloading and running of the set of scripts which constitute the
				application.</p>
		  <p><h5>Note on Git client</h5>
		  The aama project uses <a
		  href="http://github.com">GitHub</a> to store data
		  and tools; you wll need a git client in order to
		  download the tools repository and the data
		  repositories you are interested in.  Follow the
		  instructions at
		  <a href="https://help.github.com/articles/set-up-git#platform-mac">SetUp Git</a>.
		  </p>
		  <p>Note that you do not need to create a github
		  account unless you want to edit the data or code.
		  Instructions for how to do that are below.
		  </p>
		</li>
	 <ul style="list-style-type:none;">

		<li>
		  <h4>2.1 Set up aama directory</h4>
		  <p>
		    We will assume that the data is placed in a directory called 'aama-data'
                    and application software is to be placed in a directory called 
                    'webappy'. So create and switch to an <code>aama</code> directory
		    structure on your local drive, e.g.
		    <pre>
~/ $ mkdir aama-data
~/ $ mkdir webappy
~/ $ cd webappy
~/webappy/ $ mkdir bin
~/ $ cd aama-data
~/ $ aama-data/mkdir data
                    </pre>
		  </p>
		</li>
                <li>
                  <h4>2.2 Install Apache Jena Fuseki</h4>
		  <p>
		    Fuseki is the SPARQL server we are using to query the dataset.  <a
		    href="http://jena.apache.org/download/index.cgi">Download</a>
		    the current <code>apache-jena-fuseki-N.N.N-distribution</code>
		    distribution (either the zip file or the tar file; NB, make
		    sure your Java JDK is up-to-date with the download)
		    and store it in a convenient location.
		    <code>~/jena</code> is a good place.
		   The following steps will install the <code>aama</code> dataset
		    and verify that it runs. Futher information about Fuseki, 
		    as well as information and links about RDF linked data and
		    the SPARQL query language can be found at the
		    <a href="http://jena.apache.org/index.html"> Apache Jena</a> 
		    site. </p>
                  </li>

	      </ul>
	    </li>
	    <li id="datatools">
	      <h4>2.3. Download data</h4>
	      <ul style="list-style-type:none;">
		<li>
		  <p>Take a look at the <a
		  href="https://github.com/aama">Aama repositories</a> and
		  decide which languages interest you.  In general we use
		  one repository per language, or in some cases, language 
		  variety, e.g. <a
		  href="https://github.com/aama/beja-hud">beja-huda</a> is the
			  variety of Beja described by Richard Hudson in . . .
		  <a
		      href="https://github.com/aama/beja-van">beja-van</a> is the
			  variety of Beja described by . . . Verhove ub . . .
		  etc.
		  </p>
		  <p>Now you need to download the data to your local
		  harddrive.  Create a <code>data</code> directory
		  inside the <code>aama</code> directory,
		  e.g. <code>~/aama $ mkdir data</code>. Then clone
		  each language repository into the data directory:
		  </p>
		  <pre>
~/ $ cd aama-data/data
~/aama-data/data $ git clone https://github.com/aama/afar.git
~/aama-data/data $ git clone https://github.com/aama/geez.git
~/aama-data/data $ git clone https://github.com/aama/yemsa.git</pre>
		  <p>
		    Alternatively, you can create a personal github
		    account, <i>fork</i> the aama repositories (copy them
		    to your account), and then clone your repositories to
		    your local drive.  See <a
		    href="https://help.github.com/articles/fork-a-repo">Fork
		    a Repo</a> for details.
		  </p>
		</li>
		<li>
		<h4>2.4. Download Application Code</h4>

		  <p>
		    In the  <code>~/webappy</code> directory, clone the
		    aama kgithub application repository:
		    <pre>
~/aama $ git clone https://github.com/aama/webappy.git
			</pre>
		  </p>
			<p>
			The Python scripts (`.py`) will remain in this directory, while the shell and query scripts (`.sh`. `.q`) should be moved to
                    the `~/webappy/bin` subdirectory</a>
			</p>
			  
		</li>
	      </ul>
	      <p>
		When you have finished, your directory structure should look
		like this (assuming you have cloned afar, geez, and
		yemsa):
	      </p>
		<pre>
   ~/ 
   |-aama-data/
   |--data/
   |---afar/ `afar.json`, `afar.ttl`
   |---geez/ `geez.json`, `geez.ttl`	
   |---yemsa/ `yemsa.json`, `jemsa.ttl`
`  |-jena/
   |--apache-jena-fuseki-n.n.n/ aamaconfig.ttl, . . .	
   |-webappy/ pdgmDict-schemata.py, . . . ,  pdgmDisp-baseApp.py, . . .
   |---bin: fuseki.sh, . . . list-graphs.rq, . . .
		</pre>
	    </li>
	      <h4>3. Configuring Appication</h4>

	    <li id="rdfgen">
		<h4>3.1 Prepare data lists and indices</h4>
			<ol>
				<li>pdgmDict-schemata.py
					<p>. . .</p>
				</li>
				<li>pdgmDict-lexemes.py
					<p>. . .</p>
				</li>
				<li>pdgmDict-pvlists.py
					<p>. . .</p>
				</li>
			</ol>
	      <h4>3.2 Generate RDF data from morphological data files</h4>
	      <p>
		In order to convert JSON-format data files to TTL ("turtle" 
		-- a more easily human-readable RDF format), you will
		use the <code>pdgmDict-json2ttl.py</code> file in the
		 <code>webappy</code> directory. The <code>aama-datastore-update.sh</code>
                shell script will call  <code>aama-ttl2fuseki.sh</code> which in turn
		will convert the .ttl file to the rdf-xml which is needed for
		uploading to the Fuseki SPARQL service.
	      </p>
			             <p>
		   For convenience, an already-generated TTL version is included
		   with each language's JSON file.
	       Since the JSON file is the normative/persistant data format,
	       any corrections or additions you want to make should be made 
	       in this file; and if any changes are made to the SON file, you must then generate new TTL/RDF 
	       files to be  uploaded to the SPARQL server. And in fact, as 
	       long as you observe the above structure for JSON 
	       files, you can create any number of new language files of your
	       own, transform them to RDF format, and upload them to the
	       SPARQL server for querying.
	       </p>


	    </li>
	    <li>
	      <h4>3.3 Upload RDF data to SPARQL service</h4>
	      <p>
		In order to upload the RDF files to Fuseki, you must
		first start the server by running:
		<pre>
~/aama $ webappy/bin/fuseki.sh
                </pre>
		This script, like the following, assumes that the current version
		of Fuseki, for the moment <code>apache-jena-fuseki-3.16.0</code>, has
		been placed in the <code>jena</code> directory, and that
		the file <code>aamaconfig.ttl</code> has been copied
		to the Fuseki version directory; the
                scripts should be edited for the correct locations if this
		is not the case. When run for the first time, you will notice 
		that the script, which references the configuration file 
		<code>aamaconfig.ttl</code>, will have placed a, 
		for the moment empty, data
		sub-directory <code>aama</code> in the 
		<code>jena/apache-jena-fuseki-3.16.0/</code> directory.
		</p>
	      <p>
		The following script:
		<pre>
 ~/aama $ webappy/bin/aama-datastore-update.sh "../aama-datadata/[LANG]"
                </pre>
		will load the relevant LANG-pdgms.ttl file in <code>aama-data/data/[LANG]</code>
		into the Fuseki server. 
		</p>
	  <p>
	    It also automatically runs the queries <code>count-triples.rq</code>
	    ("How many triples are there in the datastore?") and 
	    <code>list-graphs.rq</code> ("What are the URIs of the 
	    language subgraphs?"), from the directory 
	    <code>webappy/bin</code>.
	    If the upload has been successful, you will see an output such as
	    the following (assuming again that afar, geez, and yemsa are the 
	    languages which have been cloned into aama/data/).</p>
	  <pre>
Query: bin/fuquery-gen.sh bin/count-triples.rq
?sTotal
33871
Query: bin/fuquery-gen.sh bin/list-graphs.rq
?g
&lt;http://oi.uchicago.edu/aama/2013/graph/afar>
&lt;http://oi.uchicago.edu/aama/2013/graph/geez>
&lt;http://oi.uchicago.edu/aama/2013/graph/yemsa>
	  </pre>
	  </p>

	    </li>
	    <li id="aamaquery">
	      <h4>4. Running the Application</h4>
	      The SPARQL service can be accessed to explore the morphological
	      data via two interfaces:
	      <ul style="list-style-type:none;">
		<li>
		  <h4>4.1The Apache Jena Fuseki interface </h4>
		  <p>
		    You can see this on your browser at 
		    <code>localhost:3030</code> after you launch Fuseki. 
		    SPARQL queries, for example, . . . , can be run directly 
		    against the datastore 
		    in the Fuseki Control Panel on the 
		    <code>localhost:3030/dataset.html</code> page
		    (select the <code>/aama</code>
		    dataset when prompted). Also the <code>pdgmDisp-...</code>
                    scripts automatically write to the terminal all SPARQL queries generated
                    in the course of the computation. These queries can be copied and
                    pasted into the Fuseki panel for inspection and debugging.
		  </p>
		  </li>
		<li>
		  <h4>4.2 An application specifically oriented to AAMA data</h4>
			<p> ### REVISE! ### </p>
		  <p>A preliminary menu-driven GUI application, will have
		    already been downloaded following the instructions outlined 
		    above in <a href="#datatools">Download data, tools, and application code</a>.
		    This application demonstrates the
		    use of SPARQL query templates for display and comparison of 
		    paradigms and morphosyntactic properties and categories. 
		    It is written in Python, which has a very engaged
		    community of users who have created a formidable,
		    and constantly growing set of libraries. However essentially
		    the same functionality could be achieved by any software
		    framework which can provide a web interface for handling
		    SPARQL queries submitted to an  RDF datastore,
		  </p>
		  <p>There are at present three major options for paradigm/mmorphology
		  	display and manipulation governed by three Python scripts. They can
		  be invoked through a menu choice, or run independently as a Python script.
		  All of them involve lining up a data framework, converting this into a
		  SPARQL query by one of the functions in <code>pdgmDispQuery.py</code>, running
		  the SkPARQL query, and displaying the result in some appropriate format.</p>
			  <p>
				  There are three governing functions (v1,v2):
			  <ol>
				  <li> A basic paradigm display function
					  <p>The function:
					  <pre>
<pdgmDisp-baseApp-PDGM.py
					  </pre>
				has as graphic setup a two-colum
				display with, in the left column, a language select-list, where a language
				choice results in a middle box display of the property-value inventory
				of the language's paradigm set, along with an indication of the order of
				properties in the value-list names of the paradigm, followed by a
				select-list of paradigm 'names'. A 'Display Paradigm' button at the
				bottom of the column results in a sequentially numbered display in
				the right text-box of the paradigm name, source, notes if present, 
				and the paradigm itself. 
               </p>
				<p>
	"APPENDIX: PARADIGMS" of the standard Indoeuropean and Afroasiatic grammars, 
				but also, e.g. 2nd millennium B.C. Sumerian [OIP; Gragg]), this is a complete 
				enumeration of the forms considered to model/exemplify a morphological system. 
				This is realized as an exhaustive set of tabular presentations each giving, 
				e.g.:
				</p>
				<ol>
				<li>
				for one possible combination out of all the relevant morphological 
				catefories: `part-of-speech`, `tense`, `aspect`, 'mood', `case`, 'inflectional
				 class`, etc. (= the `property: value' list given in the `common` portion of 
				each `termcluster` in `LANG-pdgms.json' )
					</li>
				    <li>
				    the forms associated with the possible combinations of (e.g., for verbs)
				 the `number`, `person`, `gender` properties ( = the 'terms' table [list of 
				lists] of the lexemes characterized by the 'common' property set.
					</li>
				</ol>
			  </p>
			<li>nA generalization of the notion 'paradigm'
				<p>
					In the function
					<pre>
				pdgmDisp-baseApp-GPDGM.py
					</pre>
						we have this same structure of a set of 'common'
				 property-value pairs and a "table" of 'terms', except that for the 
				properties <code>commmon</code> and 
				<code>terms</code> the set of property-values associated with each is 
				completely at the discretion of the investigator. Obviously the regular 
				paradigms of the 'LANG-pdgms.json' files are a special case of GPDGM displays, 
				as are a very large number of `common`-`term` combinations which do not 
				correspond to any possible or occurring form. But by exploring occurring 
				combinations of interest, including ones which involve distinct languages, 
				this dislay routine opens up the possibility of many potentially interesting 
				and relevant form tables.
    			</p>

				  </li>
			  
				  <li> A function to search morphological features acrod the whole datastore
					  <p>
						  The function: 
						  <pre>
pdgmDisp-formSearch.py
						  </pre>
					  is for the comparison of
realizations of a given property/value combination in different
languages. Two or more languages can be selected from the upper-right
language-selection list. In an Entry box below a list of
desired property=value combinations can be entered. A `Find Form` button
will display a list of paradigms in the designated languages where
the property=value combination list occurs. One or more of these 
paradigms can be selected, and registered by the 'Choose Paradigm' button, 
and the 'Display Paradigm' button will display the chosen paradigms in 
the lower right-side text box. Finally the paradigms in question the
be combined as in the baseApp script.
			  </p>
<p>
For example one could want to see whether second-person, feminine, 
pronominal forms, singular or plural, are distinguished in Arabic and 
Coptic-Sahidic, and compare the way they are marked. One would choose 
Arabic and Coptic-Sahidic in the language select-list, enter
 `person=Person2,gender=Fem,pos=Pronoun,number=?number` in the 'Entry'
 box, push the 'Find Forms' button and see in the upper right select
box the relevant forms, and the label  of the paradigm in which each 
form occurs. One could then select any paradigms of interest and see
the full paradigm, sequentially numbered, in the lower right-hand text 
box. For moore precise comparison one could then go on to 'combine'
the paradigms as in the baseApp script.
</p>
			  </li>
		<li>A paradigm-name generation function
			<p>
				The function:
			<pre>
pdgmDisp-pnames.py
				</pre>

simply enables the uiser to generate and display, presumably on 
an experimental basis, a "paradigm-name" list in a different order from that 
dictated by the `pdgmPropOrder` feature of the `LANG-pdgms.json` file.
			  </p>
	</li>
<li>A Query-Generating Function
	<p>
	The function called by the each of the above to generates SPaRQL queries
	
	<pre>
pdgmDispQuery.py 
    </pre>
Each of the display scripts, 3.1, 3.2, and 3.3,
finds the data it displays by running a SPARQL query against the AAMA datastore.
These queries are formed from the display data request by one or more of the
 `query()` functions contained in this script and which have been imported
into the display script. The query itself, and its CSV output, are
for the moment printed to the terrminal (or eventually to a log file).
		  </p>
</li>

		<li>
			 Generate Alternate Paradigm Name Ssequence
			  <p>To these can be added: 
				  <pre>
					  pdgmDisp-pnames
				  </pre>
			This program simply enables the uiser to generate and display, presumably on 
an experimental basis, a "paradigm-name" list in a different order from that 
dictated by the `pdgmPropOrder` feature of the `LANG-pdgms.json` file.
		  </p>
			  
		  </li>
		</ol>
	    </p>
	    <li id="aamaupdate">
	      <h4>Note: Remote Data and Webapp Update</h4>
	      <p>AAMA is an on-going project. Its data is constantly being updated,
		corrected, and added-to; the accompanying webb application
		is in a process of constant revision. 
		To ensure that your data and web app are up-to-date you should
		periodically run the following shell scripts, which assume that
		git has been installed and that the data and webapp have been
		cloned from the master version in the manner outlined above.
	      </p>
	      <p>The following script:
		<pre>
 ~/aama $ webappy/bin/aama-pulldata.sh data/[LANG]
                </pre>
		will update the JSON language data file in the
		data/[LANG] directory.
	      </p>
	      <p>While:
		<pre>
 ~/aama $ webappy/bin/aama-pulldata.sh "data/*"
                </pre>
		will update the JSON language data files in all the
		data/[LANG] directories.
	      </p>
	      <p>Once revised (or new) JSON files have been installed, remember
		to run the appropriate scripts to transform them to ttl 
		format and to load them into the SPARQL server, as outlined above.
	      </p>
	      <p>
		Finally, the script:
		<pre>
 ~/aama $ tools/bin/aama-pullwebappy.sh 
                </pre>
		will update he files of the web applicagtion.
	      </p>
	    </li>
	  </ol>

	  <h4 id="dataschema"> Appendix 1: The Data Schema </h4>
	  <p>Basic structure:</p>
	      <p>In outline 
		each language JSON file has the following structure (see any of 
		the LANGUAGE-pdgms.json files for a concrete example, and see below 
		for explanation of terms):
		</p>
	      <pre>

{
|-"lang;"        <em>"language name"</em>
|-"subfamily;"	<em>"language subfamily name"</em>			 
|-"lgpref:"       <em>"string representing 3-character ns prefix used for the 
/                  URI of language-specific morphosyntactic properties 
/                  and values"</em>
|-"datasource:"   <em>"bibliographic source(s) for the data in the file"</em>
|-"datasourceNotes:" <em>"remarks, if necessary, about darasource"</em>
|-"transcription:"  <em>"remarks, if necessary about how the transcription should be interpreted
/						w.r.t. normative AAMA transcription. (The transcription of the 'LANG-pdgms.json' file 
/	 					is always that of the datasource.)"</em>
|-"geodemoURL:"   <em>"on-line geo-/demo-graphical information about the language"</em>
|-"geodemoTXT:"   <em>"short textual summary of geo-/demographcal information"</em>
|-"schemata:" {	<em>"associative map of each morphosyntactic property used 
/                  in the inflectional paradigms with a list of its values"</em>>}
|-"lexemes:"   {  <em>"associative map of each paradigmatic 'lexeme'-ID with an indication of 
/					its lemma, gloss, part-of-speech and possibly other properties relevant to the
/				     collection of paradigms -- a provisional stand-in for a reference to a true digital lexicon".</em>}
|-"pdgmPropOrder:"  <em>"list of paradigm properties in the order their values are to be listed in paradigm labels
/		  	           (can be programatically altered)"</em>
|-"termclusters:"   {  <em>"label-ordered list of  term-clusters/paradigms,
/                   each of which has the structure:"</em>}
|----"label:"     <em>"descriptive label assigned to the term-cluster at data-entry"</em>
|----"note:"      <em>"bibliographic reference to source of paradigm data; plus other
/					remarks, if necessary"</em>
|----"common:"    <em>"map of property-value pairs which all members of the
/                 termcluster have in common"</em>
|----"terms:"     <em>"list of lists, the first of which enumerates  the
/                  properties which differentiate individual terms, while
/                  the others list, in order, the value of the i-th
/                  property -- in fact, a property-value-table realization of the distinct property-
/                  value pairs of the lexeme in question"</em>
|   }
|
| . . .
|
| ]
}

</pre>
	  <h4 id="datafilelist"> Appendix 2: The Data Files </h4>
	  <p>At present the following data files are available:</p>
	  <ul>
	    <li><a href="https://github.com/aama/aari">Aari</a></li>
	    <li><a href="https://github.com/aama/afar">Afar</a></li>
	    <li><a href="https://github.com/aama/akkadian-ob">Akkadian-ob</a></li>
	    <li><a href="https://github.com/aama/alaaba">Alaaba</a></li>
	    <li><a href="https://github.com/aama/arabic">Arabic</a></li>
	    <li><a href="https://github.com/aama/arbore">Arbore</a></li>
	    <li><a href="https://github.com/aama/awngi">Awngi</a></li>
	    <li><a href="https://github.com/aama/bayso">Bayso</a></li>
	    <li><a href="https://github.com/aama/beja-alm">Beja-alm</a></li>
	    <li><a href="https://github.com/aama/beja-hud">Beja-hud</a></li>
	    <li><a href="https://github.com/aama/beja-rei">Beja-rei</a></li>
	    <li><a href="https://github.com/aama/beja-rop">Beja-rop</a></li>
	    <li><a href="https://github.com/aama/beja-van">Beja-van</a></li>
	    <li><a href="https://github.com/aama/beja-wed">Beja-wed</a></li>
	    <li><a href="https://github.com/aama/berber-ghadames">Berber-ghadames</a></li>
	    <li><a href="https://github.com/aama/bilin">Bilin</a></li>
	    <li><a href="https://github.com/aama/boni-jara">Boni-jara</a></li>
	    <li><a href="https://github.com/aama/boni-kijee-bala">Boni-kijee-bala</a></li>
	    <li><a href="https://github.com/aama/boni-kilii">Boni-kilii</a></li>
	    <li><a href="https://github.com/aama/burji">Burji</a></li>
	    <li><a href="https://github.com/aama/burunge">Burunge</a></li>
	    <li><a href="https://github.com/aama/coptic-sahidic">Coptic-sahidic</a></li>
	    <li><a href="https://github.com/aama/dahalo">Dahalo</a></li>
	    <li><a href="https://github.com/aama/dhaasanac">Dhaasanac</a></li>
	    <li><a href="https://github.com/aama/dizi">Dizi</a></li>
	    <li><a href="https://github.com/aama/egyptian-middle">Egyptian-middle</a></li>
	    <li><a href="https://github.com/aama/elmolo">Elmolo</a></li>
	    <li><a href="https://github.com/aama/gawwada">Gawwada</a></li>
	    <li><a href="https://github.com/aama/gedeo">Gedeo</a></li>
	    <li><a href="https://github.com/aama/geez">Geez</a></li>
	    <li><a href="https://github.com/aama/hadiyya">Hadiyya</a></li>
	    <li><a href="https://github.com/aama/hausa">Hausa</a></li>
	    <li><a href="https://github.com/aama/hdi">Hdi</a></li>
	    <li><a href="https://github.com/aama/hebrew">Hebrew</a></li>
	    <li><a href="https://github.com/aama/iraqw">Iraqw</a></li>
	    <li><a href="https://github.com/aama/kambaata">Kambaata</a></li>
	    <li><a href="https://github.com/aama/kemant">Kemant</a></li>
	    <li><a href="https://github.com/aama/khamtanga">Khamtanga</a></li>
	    <li><a href="https://github.com/aama/koorete">Koorete</a></li>
	    <li><a href="https://github.com/aama/maale">Maale</a></li>
	    <li><a href="https://github.com/aama/mubi">Mubi</a></li>
	    <li><a href="https://github.com/aama/oromo">Oromo</a></li>
	    <li><a href="https://github.com/aama/rendille">Rendille</a></li>
	    <li><a href="https://github.com/aama/saho">Saho</a></li>
	    <li><a href="https://github.com/aama/shinassha">Shinassha</a></li>
	    <li><a href="https://github.com/aama/sidaama">Sidaama</a></li>
	    <li><a href="https://github.com/aama/somali">Somali</a></li>
	    <li><a href="https://github.com/aama/syriac">Syriac</a></li>
	    <li><a href="https://github.com/aama/tsamakko">Tsamakko</a></li>
	    <li><a href="https://github.com/aama/wolaytta">Wolaytta</a></li>
	    <li><a href="https://github.com/aama/yaaku">Yaaku</a></li>
	    <li><a href="https://github.com/aama/yemsa">Yemsa</a></li>
	  </ul>
	  <hr>
	</section>
      </div>

      <!-- FOOTER  -->
      <div id="footer_wrap" class="outer">
	<footer class="inner">
          <p>Published with <a href="http://pages.github.com">GitHub Pages</a></p>
	</footer>
      </div>

      

    </body>
  </html>

